# ============================================
# Duckling â€” Environment Configuration
# ============================================

# --- Core ---
DUCKLING_ENV=development
DUCKLING_LOG_LEVEL=DEBUG
DUCKLING_SECRET_KEY=change-me-in-production
DUCKLING_API_KEY=
DUCKLING_CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# --- Database ---
DATABASE_URL=sqlite+aiosqlite:///./duckling.db

# --- Redis (task queue + pub/sub) ---
REDIS_URL=redis://localhost:6379/0

# --- Slack Bot ---
SLACK_BOT_TOKEN=xoxb-your-slack-bot-token
SLACK_SIGNING_SECRET=your-slack-signing-secret
SLACK_APP_TOKEN=xapp-your-slack-app-token

# --- GitHub ---
GITHUB_TOKEN=ghp_your-github-pat
GITHUB_ORG=your-org
GITHUB_WEBHOOK_SECRET=your-webhook-secret

# --- Bitbucket ---
BITBUCKET_USERNAME=your-username
BITBUCKET_APP_PASSWORD=your-app-password
BITBUCKET_WORKSPACE=your-workspace

# --- Agent Backend ---
# Choose "opencode" (recommended), "goose", or "copilot"
AGENT_BACKEND=opencode

# --- OpenCode Agent (recommended) ---
# OpenCode supports 75+ LLM providers. Set your preferred model:
#
# Option 1: OpenCode Zen (curated models, some free)
# Sign up at https://opencode.ai/auth for a Zen API key
# OPENCODE_ZEN_API_KEY=your-zen-key
# OPENCODE_MODEL=opencode/big-pickle          # Free (limited time)
# OPENCODE_MODEL=opencode/kimi-k2.5-free      # Free (limited time)
# OPENCODE_MODEL=opencode/claude-sonnet-4-5   # Paid via Zen
#
# Option 2: Direct provider (bring your own key)
# Set the provider's API key and model:
# OPENAI_API_KEY=sk-your-key
# OPENCODE_MODEL=anthropic/claude-sonnet-4-5
#
# Option 3: OpenRouter (access to many models)
OPENAI_API_KEY=sk-or-v1-your-key
OPENAI_HOST=https://openrouter.ai/api/
OPENCODE_MODEL=deepseek/deepseek-chat-v3-0324

# --- Goose Agent (legacy) ---
# Set AGENT_BACKEND=goose to use Goose instead of OpenCode
GOOSE_PROVIDER=openai
GOOSE_MODEL=deepseek/deepseek-chat-v3-0324
ANTHROPIC_API_KEY=sk-ant-your-key
GOOSE_MAX_ITERATIONS=25
GOOSE_TIMEOUT_SECONDS=600

# --- GitHub Copilot SDK (alternative agent) ---
# Set AGENT_BACKEND=copilot to use this instead
COPILOT_MODEL=gpt-5
COPILOT_PROVIDER_TYPE=
COPILOT_OPENAI_API_KEY=

# --- Firecracker (production) ---
FIRECRACKER_BINARY=/usr/local/bin/firecracker
FIRECRACKER_KERNEL=/var/lib/duckling/vmlinux
FIRECRACKER_ROOTFS=/var/lib/duckling/rootfs.ext4
FIRECRACKER_SNAPSHOT_DIR=/var/lib/duckling/snapshots
WARM_POOL_SIZE=10
WARM_POOL_REFILL_THRESHOLD=3

# --- Docker (demo fallback) ---
DOCKER_IMAGE=duckling/agent-runner:latest
DOCKER_NETWORK=duckling-net
USE_DOCKER_FALLBACK=true

# --- Observability ---
OTEL_EXPORTER_ENDPOINT=http://localhost:4317
SENTRY_DSN=
